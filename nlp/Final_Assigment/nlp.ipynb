{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [] #Made a corpus list\n",
    "sentence = \"\"\n",
    "with open(\"text.txt\") as f:\n",
    "    lines = f.readline()\n",
    "    lines = lines.lower()\n",
    "    sentence+=lines\n",
    "word=\"\"\n",
    "for char in sentence:\n",
    "    if char == \" \" or char == \".\":\n",
    "        corpus.append(word)\n",
    "        word=\"\"\n",
    "    word+=char\n",
    "\n",
    "#Removing all the special chracters and punctuation marks using the repalce method\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    corpus[i] = corpus[i].replace(\" \",\"\")\n",
    "    corpus[i] = corpus[i].replace(\" ,\",\"\")\n",
    "    corpus[i] = corpus[i].replace(\"'' \",\"\")\n",
    "    corpus[i] = corpus[i].replace(\"'\",\"\")\n",
    "    corpus[i]=corpus[i].replace(\".\",\"\")\n",
    "    corpus[i]=corpus[i].replace(\"!\",\"\")\n",
    "    corpus[i]=corpus[i].replace(\"$\",\"\")\n",
    "    corpus[i]=corpus[i].replace(\"(\",\"\")\n",
    "    corpus[i]=corpus[i].replace(\")\",\"\")\n",
    "    corpus[i]=corpus[i].replace(\"*\",\"\")\n",
    "    corpus[i]=corpus[i].replace(\"%\",\"\")\n",
    "    corpus[i]=corpus[i].replace(\"@\",\"\")\n",
    "\n",
    "for char in corpus:\n",
    "    if char==\"\" or char==\"”\":\n",
    "        corpus.remove(char)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word sense disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cricketbat.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 45\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m synonyms\n\u001b[1;32m     43\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 45\u001b[0m     cricfile \u001b[39m=\u001b[39m codecs\u001b[39m.\u001b[39;49mopen(\u001b[39m\"\u001b[39;49m\u001b[39mcricketbat.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     46\u001b[0m     sent2 \u001b[39m=\u001b[39m cricfile\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39mlower()\n\u001b[1;32m     47\u001b[0m     vampirefile \u001b[39m=\u001b[39m codecs\u001b[39m.\u001b[39mopen(\u001b[39m\"\u001b[39m\u001b[39mvampirebat.txt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/codecs.py:905\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[39mif\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    902\u001b[0m    \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m    903\u001b[0m     \u001b[39m# Force opening of the file in binary mode\u001b[39;00m\n\u001b[1;32m    904\u001b[0m     mode \u001b[39m=\u001b[39m mode \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 905\u001b[0m file \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, mode, buffering)\n\u001b[1;32m    906\u001b[0m \u001b[39mif\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    907\u001b[0m     \u001b[39mreturn\u001b[39;00m file\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cricketbat.txt'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import codecs\n",
    "from nltk.tokenize import PunktSentenceTokenizer,sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "def filteredSentence(sentence):\n",
    "\n",
    "    filtered_sent = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(sentence)\n",
    "\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sent.append(lemmatizer.lemmatize(w))\n",
    "\n",
    "    return filtered_sent\n",
    "\n",
    "def simlilarityCheck(word1, word2):\n",
    "\n",
    "    word1 = word1 + \".n.01\"\n",
    "    word2 = word2 + \".n.01\"\n",
    "\n",
    "    try:\n",
    "        w1 = wordnet.synset(word1)\n",
    "        w2 = wordnet.synset(word2)\n",
    "\n",
    "        return w1.wup_similarity(w2)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def synonymsCreator(word):\n",
    "\n",
    "    synonyms = []\n",
    "\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for i in syn.lemmas():\n",
    "            synonyms.append(i.name())\n",
    "\n",
    "    return synonyms\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    cricfile = codecs.open(\"cricketbat.txt\", 'r', \"utf-8\")\n",
    "    sent2 = cricfile.read().lower()\n",
    "    vampirefile = codecs.open(\"vampirebat.txt\", 'r', 'utf-8')\n",
    "    sent1 = vampirefile.read().lower()\n",
    "    sent3 = \"start\"\n",
    "\n",
    "    # FOR TEST , replace the above variables with below sent1 and sent 2\n",
    "    # sent1 = \"the commercial banks are used for finance. all the financial matters are managed by financial banks and they have lots of mo\n",
    "    # sent2 = \"the river bank has water in it and it has fishes trees . lots of water is stored in the banks. boats float in it and animals\n",
    "    # sent3 = \"from which bank should i withdraw money\"\n",
    "\n",
    "    while(sent3 != \"end\"):\n",
    "\n",
    "        sent3 = input(\"Enter Query: \").lower()\n",
    "\n",
    "        filtered_sent1 = []\n",
    "        filtered_sent2 = []\n",
    "        filtered_sent3 = []\n",
    "\n",
    "        counter1 = 0\n",
    "        counter2 = 0\n",
    "        sent31_similarity = 0\n",
    "        sent32_similarity = 0\n",
    "\n",
    "        filtered_sent1 = simpleFilter(sent1)\n",
    "        filtered_sent2 = simpleFilter(sent2)\n",
    "        filtered_sent3 = simpleFilter(sent3)\n",
    "\n",
    "        for i in filtered_sent3:\n",
    "\n",
    "            for j in filtered_sent1:\n",
    "                counter1 = counter1 + 1\n",
    "                sent31_similarity = sent31_similarity + simlilarityCheck(i,j)\n",
    "\n",
    "            for j in filtered_sent2:\n",
    "                counter2 = counter2 + 1\n",
    "                sent32_similarity = sent32_similarity + simlilarityCheck(i,j)\n",
    "\n",
    "            filtered_sent1 = []\n",
    "            filtered_sent2 = []\n",
    "            filtered_sent3 = []\n",
    "\n",
    "            filtered_sent1 = filteredSentence(sent1)\n",
    "            filtered_sent2 = filteredSentence(sent2)\n",
    "            filtered_sent3 = filteredSentence(sent3)\n",
    "\n",
    "            sent1_count = 0\n",
    "            sent2_count = 0\n",
    "\n",
    "            for i in filtered_sent3:\n",
    "\n",
    "                for j in filtered_sent1:\n",
    "\n",
    "                    if(i==j):\n",
    "                        sent1_count = sent1_count + 1\n",
    "\n",
    "                for j in filtered_sent2:\n",
    "                    if(i==j):\n",
    "                        sent2_count = sent2_count + 1\n",
    "\n",
    "            if((sent1_count + sent31_similarity)>(sent2_count+sent32_similarity)):\n",
    "                print (\"Mammal Bat\")\n",
    "            else:\n",
    "                print (\"Cricket Bat\")\n",
    "\n",
    "            #-----------------------------------------------\n",
    "#Sentence1: the river bank has water in it and it has fishes trees . lots of water is stored in the banks. boats float in it and ani\n",
    "#sentence2: the commercial banks are used for finance. all the financial matters are managed by financial banks and they have lots o\n",
    "#query: from which bank should i withdraw money.\n",
    "#sen1: any of various nocturnal flying mammals of the order Chiroptera, having membranous wings that extend from the forelimbs to t\n",
    "#sen 2: a cricket wooden bat is used for playing criket. it is rectangular in shape and has handle and is made of wood or plastic a\n",
    "print (\"\\nTERMINATED\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_dataset = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n",
    "print(pos_tag_dataset[:5])\n",
    "\n",
    "random.seed(1000)\n",
    "train_set, test_set = train_test_split(pos_tag_dataset, train_size = 0.95, test_size = 0.05)\n",
    "\n",
    "print(len(train_set)) #3718\n",
    "print(len(test_set))#196\n",
    "# Split train and test set tags and tokens\n",
    "train_set_tuples = [tup for sent in train_set for tup in sent]\n",
    "test_set_tuples = [tup for sent in test_set for tup in sent]\n",
    "train_tagged_tokens = [tag[0] for tag in train_set_tuples]\n",
    "train_tagged_pos_tags = [tag[1] for tag in train_set_tuples]\n",
    "test_tagged_tokens = [tag[0] for tag in test_set_tuples]\n",
    "test_tagged_pos_tags = [tag[0] for tag in test_set_tuples]\n",
    "print(train_tagged_tokens[:10])\n",
    "print(train_tagged_pos_tags[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
